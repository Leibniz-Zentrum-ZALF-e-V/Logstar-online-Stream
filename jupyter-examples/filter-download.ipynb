{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ce9a42-939f-4cd3-9e22-2cc808ddd54a",
   "metadata": {},
   "source": [
    "# logstar data download guide\n",
    "This notebook gives you an introduction for the logstar-online-stream download tool written in python. You can find the sourcecode under: https://github.com/zalf-rdm/Logstar-online-Stream.\n",
    "Using this tool, LoraWan-sensor-data can be downloaded raw, or with \"cleaned\".\n",
    "\n",
    "**THIS NOTEBOOK IS READONLY SO IF YOU WANT WO WORK WITH IT PLEASE COPY THE NOTEBOOK**\n",
    "\n",
    "In this example notebook we're going to install and import the required python packages, download only water_content data from all stations(patches) for the duration between 2021-01-01 and 2022-01-01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1ccb4b-2e5c-4d4e-a2a9-09ccb13bee1a",
   "metadata": {},
   "source": [
    "before downloading the data we have to do some preparations. first of all install the logstar-online-stream python package with all requirements via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68234946-ed11-466a-b117-fb35f4a97b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install --force-reinstall --quiet git+https://github.com/zalf-rdm/Logstar-online-Stream.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719ddaf-010d-41a3-ac1d-ece69d57021a",
   "metadata": {},
   "source": [
    "Now we have to define the configuration which we use to download the data. API-Docs via http://dokuwiki.weather-station-data.com/doku.php?id=:en:start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162a97b-067e-4283-bf76-17f2c6a29f0d",
   "metadata": {},
   "source": [
    "## remove downloaded data if existing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27a16e-d1e3-44dd-b340-c271d792a99f",
   "metadata": {},
   "source": [
    "## Run patchcrop data download\n",
    "\n",
    "applied filters:\n",
    "* Bulk Conductivity Filter\n",
    "* water content jump filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39716232-0b7a-48fa-9ea4-96dd46a70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logstar_stream.logstar as logstar\n",
    "import logstar_stream.processing_steps.ProcessingStep as ps\n",
    "import logging\n",
    "import json\n",
    "\n",
    "stations = [\n",
    "            # weather\n",
    "            \"ws1_l1_rtu_BL\",\n",
    "            \"ws2_l1_rtu_BL\",\n",
    "            \"tbsl1_00172_BL\",\n",
    "            # stationary\n",
    "            \"tbs6a_01_180048_BL\",\n",
    "            \"tbs6a_02_180049_BL\",\n",
    "            \"tbs6a_03_180050_BL\",\n",
    "            \"tbs6a_04_180051_BL\",\n",
    "            \"tbs6a_05_180052_BL\",\n",
    "            \"tbs6a_06_180054_BL\",\n",
    "            \"tbs6a_07_180055_BL\",\n",
    "            \"tbs6a_08_180056_BL\",\n",
    "            \"tbs6a_09_180057_BL\",\n",
    "            \"tbs6a_10_180058_BL\",\n",
    "            \"tbs6a_11_180059_BL\",\n",
    "            \"tbs6a_12_180060_BL\",\n",
    "            \"tbs6a_13_180061_BL\",\n",
    "            \"tbs6a_14_180108_BL\",\n",
    "            \"tbs6a_15_180063_BL\",\n",
    "            \"tbs6a_16_180068_BL\",\n",
    "            \"tbs6a_17_180069_BL\",\n",
    "            \"tbs6a_18_180070_BL\",\n",
    "            \"tbs6a_19_180071_BL\",\n",
    "            \"tbs6a_20_180072_BL\",\n",
    "            \"tbs6a_21_180073_BL\",\n",
    "            \"tbs6a_22_180075_BL\",\n",
    "            \"tbs6a_23_180076_BL\",\n",
    "            \"tbs6a_24_180078_BL\",\n",
    "            \"tbs6a_25_180081_BL\",\n",
    "            \"tbs6a_26_180082_BL\",\n",
    "            \"tbs6a_27_180083_BL\",\n",
    "            \"tbs6a_28_180084_BL\",\n",
    "            \"tbs6a_30_180086_BL\",\n",
    "            \"tbs6a_29_180085_BL\",\n",
    "            \"tbs6a_30_180086_BL\",\n",
    "            # # mobile\n",
    "            \"wcecst_01_BL\",\n",
    "            \"wcecst_02_BL\",\n",
    "            \"wcecst_03_BL\",\n",
    "            \"wcecst_04_BL\",\n",
    "            \"wcecst_05_BL\",\n",
    "            \"wcecst_06_BL\",\n",
    "            \"wcecst_07_BL\",\n",
    "            \"wcecst_08_BL\",\n",
    "            \"wcecst_09_BL\",\n",
    "            \"wcecst_10_BL\"\n",
    "]\n",
    "conf = {\n",
    "    \"apikey\": \"\", # logstar api key\n",
    "    \"stationlist\": stations, # list of stations to process\n",
    "    \"geodata\": True, # Returns longitude and latitude of the station as well as a comment (not implemented, i guess)\n",
    "    \"datetime\": 1, #  Date and time format in the channel list: integer: 0/1\n",
    "                   #  0 (default): „dateTime“: „2020-04-01 00:00:00“\n",
    "                   #  1: „date“: „2020-04-01“, „time“: „00:00:00“ \n",
    "                   # USE 1 AS IT IS EXPECTED IN PS\n",
    "    \"startdate\": \"2020-01-01\", # Day from which the data should be retrieved in the format: YYYY-MM-DD\n",
    "    \"enddate\": \"2022-12-31\" # Day to which the data is to be retrieved in the format: YYYY-MM-DD\n",
    "}\n",
    "\n",
    "# load mapping file to translate sensor name to patch name and meassurement acronyms to names.\n",
    "sensor_mapping = \"\"\n",
    "with open(\"/home/jovyan/shared/patchcrop/patchcrop-sensor-mapping.json\") as jsonfile:\n",
    "        sensor_mapping = json.load(jsonfile)\n",
    "\n",
    "        # configure logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156250e8-78ec-4caa-bdef-392da264e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logstar_stream.processing_steps.ProcessingStep import ProcessingStep\n",
    "from re import M\n",
    "from typing import List, Dict\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class BulkConductivityDriftPS(ProcessingStep):\n",
    "    ps_name = \"BulkConductivityDriftPS\"\n",
    "\n",
    "    ps_description = \"TODO\"\n",
    "\n",
    "    # value to fill if missmeasurement detected\n",
    "    ERROR_VALUE = float(\"NaN\")\n",
    "\n",
    "    FORBIDDEN_VALUES = [{\"value\": 0, \"duration\": 100}]\n",
    "\n",
    "    treshold_left_to_right = 50\n",
    "    threshold_between_depth = 60\n",
    "    threshold_max_value = 400\n",
    "    \n",
    "    ELEMENT_ORDER_LEFT = [\n",
    "        \"bulk_conductivity_left_30_cm\",\n",
    "        \"bulk_conductivity_left_60_cm\",\n",
    "        \"bulk_conductivity_left_90_cm\",\n",
    "    ]\n",
    "    ELEMENT_ORDER_RIGHT = [\n",
    "        \"bulk_conductivity_right_30_cm\",\n",
    "        \"bulk_conductivity_right_60_cm\",\n",
    "        \"bulk_conductivity_right_90_cm\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.treshold_left_to_right = float(kwargs['treshold_left_to_right']) if \"treshold_left_to_right\" in kwargs else self.treshold_left_to_right\n",
    "        self.threshold_between_depth = float(kwargs['threshold_between_depth']) if \"threshold_between_depth\" in kwargs else self.threshold_between_depth\n",
    "        self.threshold_max_value = float(kwargs['threshold_max_value']) if \"threshold_max_value\" in kwargs else self.threshold_max_value\n",
    "\n",
    "        self.to_change = []\n",
    "\n",
    "    def compare_and_prepare_to_change(self, row, row_num):\n",
    "        \n",
    "        for i in range(3):\n",
    "            left_value = row[self.ELEMENT_ORDER_LEFT[i]]\n",
    "            right_value = row[self.ELEMENT_ORDER_RIGHT[i]]\n",
    "\n",
    "            left_del = False\n",
    "            right_del = False\n",
    "\n",
    "            if math.isnan(left_value):\n",
    "                pass\n",
    "            # compare diff between left and right side. If left or right higher than treshold_left_to_right + (left or right) remove the other\n",
    "            elif left_value - right_value > self.treshold_left_to_right or left_value > self.threshold_max_value:\n",
    "                    left_del = True\n",
    "                    self.to_change.append((int(row_num), self.ELEMENT_ORDER_LEFT[i]))\n",
    "            \n",
    "            if math.isnan(right_value):\n",
    "                pass\n",
    "            elif right_value - left_value > self.treshold_left_to_right or right_value > self.threshold_max_value:\n",
    "                    right_del = True\n",
    "                    self.to_change.append((int(row_num), self.ELEMENT_ORDER_RIGHT[i]))\n",
    "\n",
    "            # if 30cm depth\n",
    "            if i == 0: \n",
    "              continue\n",
    "\n",
    "\n",
    "            # check distance between depth and next depth is lower than threshold_between_depth\n",
    "            left_lower_value = row[self.ELEMENT_ORDER_LEFT[i - 1]]\n",
    "            right_lower_value = row[self.ELEMENT_ORDER_RIGHT[i - 1]]\n",
    "            \n",
    "            # check if nan or none is on left side\n",
    "            if  None in (left_value, left_lower_value) or math.isnan(left_value) or math.isnan(left_lower_value):\n",
    "                pass\n",
    "            \n",
    "            elif left_lower_value + self.threshold_between_depth < left_value and not left_del:\n",
    "                self.to_change.append((int(row_num), self.ELEMENT_ORDER_LEFT[i]))\n",
    "                \n",
    "            if  None in (right_value, right_lower_value) or math.isnan(right_value) or math.isnan(right_lower_value):\n",
    "                pass\n",
    "            \n",
    "            elif right_lower_value + self.threshold_between_depth < right_value and not right_del:\n",
    "                self.to_change.append((int(row_num), self.ELEMENT_ORDER_RIGHT[i]))\n",
    "            \n",
    "            \n",
    "\n",
    "    def process(self, df: pd.DataFrame, station: str):\n",
    "        logging.debug(f\"parsing data for station {station} ...\")\n",
    "\n",
    "        # check if all required fields are available\n",
    "        all_requested_columns_available = set(\n",
    "            self.ELEMENT_ORDER_LEFT + self.ELEMENT_ORDER_RIGHT\n",
    "        ).issubset(df.columns)\n",
    "        if not all_requested_columns_available:\n",
    "            logging.debug(\n",
    "                f\"did not found all required columns in {station} to run {self.ps_name}\"\n",
    "            )\n",
    "            return df\n",
    "\n",
    "        if df is None:\n",
    "            return None\n",
    "        # iterate over each row of the given data\n",
    "        for row_num, row in df.iterrows():\n",
    "          [self.compare_and_prepare_to_change(row, row_num)]\n",
    "\n",
    "        # run do change for all to change values\n",
    "        [\n",
    "            self.__do_change__(df, row_num, column_name)\n",
    "            for row_num, column_name in self.to_change\n",
    "        ]\n",
    "        self.to_change = []\n",
    "        # write logs\n",
    "        self.write_log(station)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d0926-5b48-4e3e-b31f-ba71da076c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 13:05:26,737 downloading data for station patch_51 from 2020-01-01 to 2022-12-31 ...\n"
     ]
    }
   ],
   "source": [
    "! rm data/* logs/*\n",
    "BULK_CONDUCTIVITY_THRESHOLD_BETWEEN_LEFT_RIGHT = 50\n",
    "BULK_CONDUCTIVITY_THRESHOLD_BETWEEN_DEPTH = 80\n",
    "BULK_CONDUCTIVITY_THRESHOLD_MAX_VALUE  = 300 # Maximum allow BC if above it will be filtered out  \n",
    "processing_steps = [\n",
    "                    ps.load_class([\"JumpCheckPS\"]), \n",
    "                   BulkConductivityDriftPS({\"treshold_left_to_right\": BULK_CONDUCTIVITY_THRESHOLD_BETWEEN_LEFT_RIGHT, \n",
    "                                            \"threshold_between_depth\": BULK_CONDUCTIVITY_THRESHOLD_BETWEEN_DEPTH,\n",
    "                                            \"threshold_max_value\": BULK_CONDUCTIVITY_THRESHOLD_MAX_VALUE\n",
    "                                           })\n",
    "]\n",
    "\n",
    "\n",
    "df_dict = logstar.manage_dl_db( conf,                              # configuration\n",
    "                                processing_steps=processing_steps, # loaded processing steps\n",
    "                                sensor_mapping=sensor_mapping,     # translation file\n",
    "                                csv_folder=\"data/\")                # folder to write csv files to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d161857-1476-48be-91c5-672ab4d7b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PLOT\n",
    "import datetime\n",
    "columns = [\n",
    "        'date',\n",
    "        'time',\n",
    "        \"bulk_conductivity_left_30_cm\",\n",
    "        \"bulk_conductivity_left_60_cm\",\n",
    "        \"bulk_conductivity_left_90_cm\",\n",
    "        \"bulk_conductivity_right_30_cm\",\n",
    "        \"bulk_conductivity_right_60_cm\",\n",
    "        \"bulk_conductivity_right_90_cm\"\n",
    "]\n",
    "\n",
    "df = df_dict['patch_12'].loc[:,columns]\n",
    "df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\").dt.date\n",
    "df = df[(df['date']>datetime.date(2020,1,1)) & (df['date']<datetime.date(2023,3,1))]\n",
    "# plot the data (docs: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)\n",
    "fig = df.plot(x=\"date\", \n",
    "              figsize=(24,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb4c1d-560d-4adb-af58-ca297cdfb266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
